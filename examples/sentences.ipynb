{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2393ea16-c25b-4e5e-852e-6682b3f6e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from os import chdir\n",
    "import re\n",
    "from urllib.parse import urlsplit, urlunsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27719a9-48f9-4634-abc8-a9cc9551f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('/mnt/tmpfs/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac9a493-4274-47a6-8b13-55ebbd92d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following configuration works well on machines with 256 cores and 1TB memory.\n",
    "# It configures Spark in local mode and uses all the available resources.\n",
    "# To run it on a machine with less memory available, please reduce spark.executor.memory & spark.driver.memory,\n",
    "# and increase spark.default.parallelism & spark.sql.shuffle.partitions to reduce the memory demand.\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.executor.memory\", \"1000g\") \\\n",
    "    .config(\"spark.driver.memory\", \"1000g\") \\\n",
    "    .config(\"spark.local.dir\", \"/mnt/vol1/tmp\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf3bda4-0508-449f-8378-72d900caf016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:4041 256\n"
     ]
    }
   ],
   "source": [
    "# Spark UI url\n",
    "\n",
    "sparkUrlParts = list(urlsplit(sc.uiWebUrl))\n",
    "sparkUrlParts[1] = re.sub('^[^:]*', 'localhost', sparkUrlParts[1])\n",
    "sparkUrl = urlunsplit(sparkUrlParts)\n",
    "\n",
    "print(sparkUrl, sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519c6ff3-769e-487d-94d4-1dbd7b084a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all the corpus csv.\n",
    "\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"./corpus\")\n",
    "\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03a45c7-0fa0-43da-8e40-3526ed014dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation\n",
    "# print(\"Missing title\", df.filter(df.title.isNull()).count(), \"Missing text\", df.filter(df.text.isNull()).count())\n",
    "\n",
    "# Keep minimal data in memory.\n",
    "df = df.select(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad61d540-bbc6-4b60-91e3-82431d773f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|                                    col|\n",
      "+---------------------------------------+\n",
      "|                               選舉快訊|\n",
      "|                       左派鐵票排山倒海|\n",
      "|                               陳太勢危|\n",
      "|                                 本報訊|\n",
      "|             今日舉行的立法會港島區補選|\n",
      "|                               形勢緊湊|\n",
      "|                       截至下午3:30為止|\n",
      "|                                   有27|\n",
      "|                            51%選民投票|\n",
      "|  雖然今日上半天投票率高於上月舉行的...|\n",
      "|      但較2004年立法會選舉同時間的投...|\n",
      "|   部份為陳方安生拉票的泛民主派成員指出|\n",
      "|                 上半日投票率略高於預期|\n",
      "|         很大程度是左派製造的動員票所致|\n",
      "|                   現時陳太形勢仍然危急|\n",
      "|                 未投票的選民應盡快行動|\n",
      "|                 對抗左派排山倒海的鐵票|\n",
      "|前任政務司司長陳方安生今晨7時許步出家門|\n",
      "|                           一身鮮紅衣裳|\n",
      "|         在子女及公民黨黨魁余若薇陪同下|\n",
      "+---------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the corpus by punctuations to find all the sentense.\n",
    "punc = \"[ 　,.\\u2000-\\u206F\\u3002\\uff1f\\uff01\\uff0c\\u3001\\uff1b\\uff1a\\u201c\\u201d\\u2018\\u2019\\uff08\\uff09\\u300a\\u300b\\u3008\\u3009\\u3010\\u3011\\u300e\\u300f\\u300c\\u300d\\ufe43\\ufe44\\u3014\\u3015\\u2026\\u2014\\uff5e\\ufe4f\\uffe5\\\"']\"\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"sentence\", pattern=punc, gaps=True, minTokenLength=2, toLowercase=False)\n",
    "sentence_df = regexTokenizer.transform(df).select(explode(\"sentence\"))\n",
    "\n",
    "sentence_df.cache()\n",
    "sentence_df.count()\n",
    "\n",
    "sentence_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ccf7161-60d7-4d57-8343-f1a8beefe2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.repartition(5).write \\\n",
    "    .option(\"header\", False) \\\n",
    "    .csv(\"sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ec625-78ec-425a-939d-0d2d0efb8948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
