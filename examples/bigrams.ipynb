{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2393ea16-c25b-4e5e-852e-6682b3f6e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from os import chdir\n",
    "import re\n",
    "from urllib.parse import urlsplit, urlunsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac9a493-4274-47a6-8b13-55ebbd92d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following configuration works well on machines with 256 cores and 1TB memory.\n",
    "# It configures Spark in local mode and uses all the available resources.\n",
    "# To run it on a machine with less memory available, please reduce spark.executor.memory & spark.driver.memory,\n",
    "# and increase spark.default.parallelism & spark.sql.shuffle.partitions to reduce the memory demand.\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.executor.memory\", \"1000g\") \\\n",
    "    .config(\"spark.driver.memory\", \"1000g\") \\\n",
    "    .config(\"spark.local.dir\", \"/mnt/vol1/tmp\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf3bda4-0508-449f-8378-72d900caf016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:4041 256\n"
     ]
    }
   ],
   "source": [
    "# Spark UI url\n",
    "\n",
    "sparkUrlParts = list(urlsplit(sc.uiWebUrl))\n",
    "sparkUrlParts[1] = re.sub('^[^:]*', 'localhost', sparkUrlParts[1])\n",
    "sparkUrl = urlunsplit(sparkUrlParts)\n",
    "\n",
    "print(sparkUrl, sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519c6ff3-769e-487d-94d4-1dbd7b084a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all the corpus csv.\n",
    "\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"../corpus\")\n",
    "\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03a45c7-0fa0-43da-8e40-3526ed014dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation\n",
    "# print(\"Missing title\", df.filter(df.title.isNull()).count(), \"Missing text\", df.filter(df.text.isNull()).count())\n",
    "\n",
    "# Keep minimal data in memory.\n",
    "df = df.select(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad61d540-bbc6-4b60-91e3-82431d773f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[char: array<string>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the corpus\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"char\", pattern=\".\", gaps=False, minTokenLength=1, toLowercase=False)\n",
    "char_df = regexTokenizer.transform(df).select(\"char\")\n",
    "\n",
    "char_df.cache()\n",
    "# char_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ce9ca3-c12d-4b81-be69-b9e6d24b3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ngram(n):\n",
    "    ngram_gen = NGram(n=n, inputCol=\"char\", outputCol=\"ngrams_list\")\n",
    "    ngram_df = ngram_gen.transform(char_df).select(explode('ngrams_list').alias('ngrams'))\n",
    "    ngram_df = ngram_df.groupBy('ngrams').count()\n",
    "    \n",
    "    return ngram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4daacd64-8b16-4e1c-8851-717af3d6d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-ngram...\n",
      "Generating 2-ngram...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[ngrams: string, count: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate ngram with different lengths\n",
    "\n",
    "ngram_result_df = None\n",
    "ngram_max_len = 2\n",
    "\n",
    "for n in range(1, ngram_max_len + 1):\n",
    "    print(\"Generating \" + str(n) + \"-ngram...\")\n",
    "    ngram_n_df = gen_ngram(n)\n",
    "    if ngram_result_df == None:\n",
    "        ngram_result_df = ngram_n_df\n",
    "    else:\n",
    "        ngram_result_df = ngram_result_df.unionByName(ngram_n_df)\n",
    "        \n",
    "ngram_result_df = ngram_result_df.orderBy(col(\"count\").desc())\n",
    "ngram_result_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d8e9f8-5582-4d03-a4c9-d0929e38791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5544299"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Spark calcuation\n",
    "ngram_result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17752746-acef-4f96-beb7-d320e81dad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the result into Pythonland for processing.\n",
    "ngram_result_rows = ngram_result_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "172b4159-c1b2-409e-8161-dc8a9d4e7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rows into a Counter dict.\n",
    "\n",
    "ngram_result_dict = Counter()\n",
    "\n",
    "for row in ngram_result_rows:\n",
    "    ngrams_str = row.ngrams[::2] # NGram inserts space between chars. Remove them.\n",
    "    has_ascii = any(ord(c) < 256 for c in ngrams_str)\n",
    "    if ' ' in ngrams_str or has_ascii: continue # Filter out any strings containing space\n",
    "    ngram_result_dict[ngrams_str] = row['count']\n",
    "    # Calculate total count of single char.\n",
    "    if len(ngrams_str) == 1:\n",
    "        ngram_result_dict[ngrams_str[:-1]] += row['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70968c4a-4897-43cc-9192-c2a309dc04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate freqency from count\n",
    "\n",
    "ngram_prob_dict = dict()\n",
    "\n",
    "for ngram_str in ngram_result_dict:\n",
    "    if ngram_str == '': continue\n",
    "    parent_freq = ngram_result_dict[ngram_str[:-1]]\n",
    "    if parent_freq == 0: continue\n",
    "    ngram_prob_dict[ngram_str] = ngram_result_dict[ngram_str] / parent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f00b71-2f06-470a-b4d9-88bda1b9d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the result into a csv file.\n",
    "\n",
    "output_path = \"apple_bigram.csv\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"ngram,freq\\n\")\n",
    "    for k in ngram_prob_dict:\n",
    "        f.write(k + \",\" + str(ngram_prob_dict[k]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d4ad6-020a-47dd-90cf-5ef6e83b9f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
