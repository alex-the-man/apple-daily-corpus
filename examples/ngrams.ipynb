{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2393ea16-c25b-4e5e-852e-6682b3f6e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from os import chdir\n",
    "import re\n",
    "from urllib.parse import urlsplit, urlunsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac9a493-4274-47a6-8b13-55ebbd92d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following configuration works well on machines with 256 cores and 1TB memory.\n",
    "# It configures Spark in local mode and uses all the available resources.\n",
    "# To run it on a machine with less memory available, please reduce spark.executor.memory & spark.driver.memory,\n",
    "# and increase spark.default.parallelism & spark.sql.shuffle.partitions to reduce the memory demand.\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.executor.memory\", \"1000g\") \\\n",
    "    .config(\"spark.driver.memory\", \"1000g\") \\\n",
    "    .config(\"spark.local.dir\", \"/mnt/vol1/tmp\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf3bda4-0508-449f-8378-72d900caf016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:4040 256\n"
     ]
    }
   ],
   "source": [
    "# Spark UI url\n",
    "\n",
    "sparkUrlParts = list(urlsplit(sc.uiWebUrl))\n",
    "sparkUrlParts[1] = re.sub('^[^:]*', 'localhost', sparkUrlParts[1])\n",
    "sparkUrl = urlunsplit(sparkUrlParts)\n",
    "\n",
    "print(sparkUrl, sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519c6ff3-769e-487d-94d4-1dbd7b084a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all the corpus csv.\n",
    "\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"../corpus\")\n",
    "\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03a45c7-0fa0-43da-8e40-3526ed014dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation\n",
    "# print(\"Missing title\", df.filter(df.title.isNull()).count(), \"Missing text\", df.filter(df.text.isNull()).count())\n",
    "\n",
    "# Keep minimal data in memory.\n",
    "df = df.select(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad61d540-bbc6-4b60-91e3-82431d773f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[char: array<string>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the corpus\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"char\", pattern=\".\", gaps=False, minTokenLength=1, toLowercase=False)\n",
    "char_df = regexTokenizer.transform(df).select(\"char\")\n",
    "\n",
    "char_df.cache()\n",
    "# char_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ce9ca3-c12d-4b81-be69-b9e6d24b3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate and count all ngrams then write them to a single csv.\n",
    "char_blacklist = \"[\\u0000-\\u0019\\u0021-\\u00FF\\u2000-\\u206F\\u3002\\uff1f\\uff01\\uff0c\\u3001\\uff1b\\uff1a\\u201c\\u201d\\u2018\\u2019\\uff08\\uff09\\u300a\\u300b\\u3008\\u3009\\u3010\\u3011\\u300e\\u300f\\u300c\\u300d\\ufe43\\ufe44\\u3014\\u3015\\u2026\\u2014\\uff5e\\ufe4f\\uffe5\\\"']\"\n",
    "\n",
    "def gen_ngram(n):\n",
    "    ngram_gen = NGram(n=n, inputCol=\"char\", outputCol=\"ngrams_list\")\n",
    "    ngram_df = ngram_gen.transform(char_df).select(explode('ngrams_list').alias('ngrams'))\n",
    "    # ngram_df = ngram_df.groupBy('ngrams').count().orderBy(col(\"count\").desc())\n",
    "    ngram_df = ngram_df.filter(~col('ngrams').rlike(char_blacklist)) # Remove ngrams with blacklisted chars.\n",
    "    ngram_df = ngram_df.groupBy('ngrams').count()\n",
    "    \n",
    "    if n > 1:\n",
    "        ngram_df = ngram_df.filter(ngram_df['count'] >= 10)\n",
    "    \n",
    "    return ngram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4daacd64-8b16-4e1c-8851-717af3d6d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-ngram...\n",
      "Generating 2-ngram...\n",
      "Generating 3-ngram...\n",
      "Generating 4-ngram...\n",
      "Generating 5-ngram...\n",
      "Generating 6-ngram...\n",
      "Generating 7-ngram...\n",
      "Generating 8-ngram...\n",
      "Generating 9-ngram...\n",
      "Generating 10-ngram...\n",
      "Generating 11-ngram...\n",
      "Generating 12-ngram...\n",
      "Generating 13-ngram...\n",
      "Generating 14-ngram...\n",
      "Generating 15-ngram...\n",
      "Generating 16-ngram...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[ngrams: string, count: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate ngram with different lengths\n",
    "\n",
    "ngram_result_df = None\n",
    "ngram_max_len = 16\n",
    "\n",
    "for n in range(1, ngram_max_len + 1):\n",
    "    print(\"Generating \" + str(n) + \"-ngram...\")\n",
    "    ngram_n_df = gen_ngram(n)\n",
    "    if ngram_result_df == None:\n",
    "        ngram_result_df = ngram_n_df\n",
    "    else:\n",
    "        ngram_result_df = ngram_result_df.unionByName(ngram_n_df)\n",
    "        \n",
    "ngram_result_df = ngram_result_df.orderBy(col(\"count\").desc())\n",
    "ngram_result_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d8e9f8-5582-4d03-a4c9-d0929e38791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21757817"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Spark calcuation\n",
    "ngram_result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17752746-acef-4f96-beb7-d320e81dad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the result into Pythonland for processing.\n",
    "ngram_result_rows = ngram_result_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "172b4159-c1b2-409e-8161-dc8a9d4e7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rows into a Counter dict.\n",
    "\n",
    "ngram_result_dict = Counter()\n",
    "\n",
    "for row in ngram_result_rows:\n",
    "    ngrams_str = row.ngrams[::2] # NGram inserts space between chars. Remove them.\n",
    "    if ' ' in ngrams_str: continue # Filter out any strings containing space\n",
    "    ngram_result_dict[ngrams_str] = row['count']\n",
    "    \n",
    "all_ngrams = sorted(ngram_result_dict.keys(), key=len, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70968c4a-4897-43cc-9192-c2a309dc04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ngrams dataframe contains a lot of duplicated substring. e.g. for string ABC, substring AB and BC are also present in the dataframe.\n",
    "# Remove these substrings.\n",
    "\n",
    "def window(seq, n=2):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield \"\".join(result)\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield \"\".join(result)\n",
    "        \n",
    "for text in all_ngrams:\n",
    "    freq = ngram_result_dict.get(text, 0)\n",
    "    if freq <= 0: continue\n",
    "    if len(text) < 3: continue\n",
    "    # print(text, freq)\n",
    "    max_n = len(text) - 1\n",
    "    for substr in window(text, max_n):\n",
    "        substring_freq = ngram_result_dict.get(substr, 0)\n",
    "        if substring_freq == 0: continue\n",
    "\n",
    "        substring_freq_ratio = substring_freq / freq\n",
    "        if substring_freq_ratio < 1.5:\n",
    "            # print(\"delete\", substr, substring_freq, freq)\n",
    "            del ngram_result_dict[substr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f00b71-2f06-470a-b4d9-88bda1b9d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the result into a csv file.\n",
    "\n",
    "output_path = \"apple_ngram_1_16.csv\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"ngram,count\\n\")\n",
    "    for (k, v) in ngram_result_dict.most_common():\n",
    "        if v < 100 or len(k) == ngram_max_len: continue\n",
    "        # if k not in word_set: continue\n",
    "        f.write(k + \",\" + str(v) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ec625-78ec-425a-939d-0d2d0efb8948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
